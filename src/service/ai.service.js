const { createOpenAI } = require('@ai-sdk/openai');
const { streamText, convertToModelMessages, generateText } = require('ai');
const { ollamaBaseURL } = require('@/constants/urls');
const Utils = require('@/utils');
// åˆ›å»º Ollama çš„ OpenAI å…¼å®¹å®ä¾‹
// å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®è¿œç¨‹ Ollama æœåŠ¡å™¨
// æœ¬åœ°: http://localhost:11434/v1
// è¿œç¨‹(winæœ¬): http://192.168.3.10:11434/v1
const ollama = createOpenAI({
  baseURL: ollamaBaseURL,
  apiKey: 'ollama', // Ollama ä¸éœ€è¦çœŸå®çš„ API keyï¼Œä½† SDK è¦æ±‚æä¾›
});

console.log(`Ollama æœåŠ¡åœ°å€: ${ollamaBaseURL}`);

class AiService {
  // å¥åº·æ£€æŸ¥ï¼šæµ‹è¯• Ollama æœåŠ¡æ˜¯å¦å¯ç”¨
  checkHealth = async () => {
    try {
      // å°è¯•è·å–æ¨¡å‹åˆ—è¡¨æ¥éªŒè¯æœåŠ¡æ˜¯å¦å¯ç”¨
      const baseUrl = ollamaBaseURL.replace('/v1', '');
      const res = await fetch(`${baseUrl}/api/tags`, {
        method: 'GET',
        signal: AbortSignal.timeout(5000), // è®¾å®š5ç§’è¶…æ—¶
      });

      if (!res.ok) {
        throw new Error(`Health check failed with status: ${res.status}`);
      }

      const data = await res.json();
      // æŒ‰éƒ¨ç½²æ—¶é—´å€’åºæ’åºï¼Œå…ˆéƒ¨ç½²çš„æ¨¡å‹æ’åœ¨å‰é¢
      const models = data.models
        .toSorted((a, b) => new Date(a.modified_at) - new Date(b.modified_at))
        .map(({ model }) => ({
          name: model.split(':')[0],
          value: model,
        }));
      console.log(`âœ… [Health Check] Ollama is running, models: ${JSON.stringify(models)}`);
      return [true, models];
    } catch (error) {
      console.warn(`âš ï¸ [Health Check] Ollama is not available:`, error.message);
      return [false, []];
    }
  };

  /**
   * æµå¼å¯¹è¯æ¥å£
   * @param {Array} messages - æ¶ˆæ¯å†å² [{role: 'user', content: '...'}, ...]
   * @param {String} model - æ¨¡å‹åç§°, é»˜è®¤ä¸º qwen2.5:7b
   * @param {String} context - æ–‡ç« å†…å®¹ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
   */
  streamChat = async (messages, model = 'qwen2.5:7b', context = null) => {
    // streamChat = async (messages, model = 'deepseek-r1:8b', context = null) => {
    try {
      console.log(`\nğŸ¤– [AI Request] æ¨¡å‹: ${model}, æ¶ˆæ¯æ•°: ${messages.length}`);
      const startTime = Date.now();

      // ç»„è£…ç³»ç»Ÿæç¤º
      let systemPrompt = 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ“…é•¿è§£é‡Šä»£ç ã€æ€»ç»“æ–‡ç« å’Œå›ç­”æŠ€æœ¯é—®é¢˜ã€‚';
      // å¦‚æœæœ‰æ–‡ç« ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°ç³»ç»Ÿæç¤ºä¸­
      if (context) {
        // 1. æ¸…ç† HTML æ ‡ç­¾ (ä½¿ç”¨ Utils ä¸­ä¿ç•™ç»“æ„çš„æ¸…æ´—æ–¹æ³•)
        let cleanContext = Utils.cleanTextForAI(context);

        // console.log('ğŸ§¹ [AI Service] HTML å†…å®¹å·²æ¸…ç†, åŸå§‹é•¿åº¦:', context.length, '-> æ¸…ç†å:', cleanContext.length);

        // 2. é™åˆ¶æ–‡ç« å†…å®¹é•¿åº¦ï¼Œé¿å…è¶…å‡ºä¸Šä¸‹æ–‡çª—å£
        // Qwen2.5 æ”¯æŒè¾ƒé•¿ä¸Šä¸‹æ–‡ (é€šå¸¸ 32k-128k)ï¼Œè¿™é‡Œè®¾ç½®æ›´å®½æ¾çš„é™åˆ¶
        const maxContextLength = 50000; // çº¦ 50000 å­—ç¬¦ (å®‰å…¨èŒƒå›´å†…)
        const truncatedContext = cleanContext.length > maxContextLength ? cleanContext.substring(0, maxContextLength) + '...\n[æ–‡ç« å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­]' : cleanContext;

        systemPrompt += `\n\nå½“å‰æ–‡ç« å†…å®¹ï¼š\n${truncatedContext}\n\nè¯·åŸºäºè¿™ç¯‡æ–‡ç« çš„å†…å®¹æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`;
      }

      // å¯¹è¯å†å²ç®¡ç†ï¼šä¿ç•™æœ€è¿‘çš„ 10 è½®å¯¹è¯ï¼ˆ20 æ¡æ¶ˆæ¯ï¼‰
      const maxMessages = 20;
      const managedMessages = messages.length > maxMessages ? messages.slice(-maxMessages) : messages;

      const result = await streamText({
        model: ollama.chat(model), // æ˜ç¡®ä½¿ç”¨ chat æ–¹æ³•
        system: systemPrompt,
        // v6 ä¸­ convertToModelMessages è¿”å› Promiseï¼Œéœ€è¦ await
        messages: await convertToModelMessages(managedMessages),
        // å¯é€‰ï¼šè®¾ç½®æ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆéœ€è¦ Ollama æ”¯æŒï¼‰
        maxTokens: 4096, // æœ€å¤§è¾“å‡º tokens
      });

      const endTime = Date.now();
      console.log(`âœ… [AI Response] è¯·æ±‚å®Œæˆ, è€—æ—¶: ${endTime - startTime}ms`);

      // ç›´æ¥è¿”å› result å¯¹è±¡ï¼Œè®© Controller å¤„ç†å“åº”æµ
      return result;
    } catch (error) {
      console.error('âŒ [AI Service Error]', error);

      // è¯¦ç»†çš„é”™è¯¯åˆ†ç±»å’Œå‹å¥½æç¤º
      let errorMessage = 'AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨';
      let errorCode = 'AI_SERVICE_ERROR';

      // æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„æç¤º
      // æ³¨ï¼šä»¥ä¸‹é”™è¯¯ç æ˜¯ Node.js ç³»ç»Ÿçº§ç½‘ç»œé”™è¯¯ç ï¼ˆéæ¡†æ¶ç‰¹æœ‰ï¼‰
      // ECONNREFUSED - è¿æ¥è¢«æ‹’ç»ï¼ˆç›®æ ‡ç«¯å£æœªç›‘å¬ï¼‰
      // ETIMEDOUT - è¿æ¥è¶…æ—¶ï¼ˆç½‘ç»œå»¶è¿Ÿæˆ–æœåŠ¡å™¨æ— å“åº”ï¼‰
      // ENOTFOUND - DNS è§£æå¤±è´¥ï¼ˆä¸»æœºåä¸å­˜åœ¨ï¼‰
      if (error.message.includes('ECONNREFUSED') || error.message.includes('connect')) {
        errorMessage = `AI æœåŠ¡å™¨è¿æ¥å¤±è´¥ (${ollamaBaseURL})ã€‚è¯·æ£€æŸ¥ï¼š1. Ollama æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼Ÿ3. æœåŠ¡å™¨åœ°å€æ˜¯å¦æ­£ç¡®ï¼Ÿ`;
        errorCode = 'CONNECTION_REFUSED';
      } else if (error.message.includes('timeout') || error.message.includes('ETIMEDOUT')) {
        errorMessage = 'AI æœåŠ¡å™¨å“åº”è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•';
        errorCode = 'TIMEOUT';
      } else if (error.message.includes('ENOTFOUND')) {
        errorMessage = `æ— æ³•è§£æ AI æœåŠ¡å™¨åœ°å€ (${ollamaBaseURL})ï¼Œè¯·æ£€æŸ¥é…ç½®`;
        errorCode = 'HOST_NOT_FOUND';
      } else if (error.message.includes('model')) {
        errorMessage = `æ¨¡å‹ "${model}" æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä¸‹è½½: ollama pull ${model}`;
        errorCode = 'MODEL_NOT_FOUND';
      }

      const customError = new Error(errorMessage);
      customError.code = errorCode;
      customError.originalError = error.message;
      throw customError;
    }
  };

  /**
   * ç¼–è¾‘è¡¥å…¨æ¥å£ï¼ˆéæµå¼ï¼Œå¿«é€Ÿå“åº”ï¼‰
   * @param {String} beforeText - å…‰æ ‡å‰æ–‡æœ¬ï¼ˆæœ€å¤š 500 å­—ï¼‰
   * @param {String} afterText - å…‰æ ‡åæ–‡æœ¬ï¼ˆå¯é€‰ï¼Œæœ€å¤š 200 å­—ï¼‰
   * @param {String} model - æ¨¡å‹åç§°
   * @param {Number} maxSuggestions - å»ºè®®æ•°é‡ï¼ˆé»˜è®¤ 3ï¼‰
   * @returns {Promise<Array>} è¡¥å…¨å»ºè®®æ•°ç»„
   */
  getCompletion = async (beforeText, afterText = '', model = 'qwen2.5:7b', maxSuggestions = 3) => {
    try {
      console.log(`\nâœï¸ [AI Completion] æ¨¡å‹: ${model}, ä¸Šæ–‡é•¿åº¦: ${beforeText.length}, ä¸‹æ–‡é•¿åº¦: ${afterText.length}`);
      const startTime = Date.now();

      // ç»„è£…ä¸“é—¨çš„è¡¥å…¨æç¤º
      const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªå†™ä½œè¡¥å…¨åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆ ${maxSuggestions} ä¸ªç»­å†™å»ºè®®ã€‚

è§„åˆ™ï¼š
1. æ¯ä¸ªå»ºè®®æ§åˆ¶åœ¨ 1-30 å­—ä¹‹é—´
2. å»ºè®®åº”è‡ªç„¶è¡”æ¥ä¸Šæ–‡ï¼Œè¯­ä¹‰è¿è´¯
3. æŒ‰é•¿åº¦ä»çŸ­åˆ°é•¿æ’åºï¼ˆè¯ -> çŸ­è¯­ -> å¥å­ï¼‰
4. åªè¿”å›è¡¥å…¨å†…å®¹æœ¬èº«ï¼Œä¸è¦è§£é‡Šæˆ–æ·»åŠ æ ‡ç‚¹ï¼ˆé™¤éå¿…è¦ï¼‰
5. å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ ¼å¼

è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
{"suggestions": ["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]}`;

      // ç»„è£…ç”¨äºè¡¥å…¨çš„Prompt
      let userPrompt = `ä¸Šæ–‡å†…å®¹ï¼š
"""
${beforeText}
"""`;

      if (afterText) {
        userPrompt += `

ä¸‹æ–‡å†…å®¹ï¼š
"""
${afterText}
"""`;
      }

      userPrompt += `

è¯·æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆ ${maxSuggestions} ä¸ªç»­å†™å»ºè®®ï¼ˆJSON æ ¼å¼ï¼‰ï¼š`;

      const result = await generateText({
        model: ollama.chat(model),
        system: systemPrompt,
        prompt: userPrompt,
        maxTokens: 200, // é™åˆ¶ç”Ÿæˆé•¿åº¦ï¼Œç¡®ä¿å¿«é€Ÿå“åº”
      });

      const endTime = Date.now();
      console.log(`âœ… [AI Completion] è¯·æ±‚å®Œæˆ, è€—æ—¶: ${endTime - startTime}ms`);
      console.log(`ğŸ“ [AI Completion] åŸå§‹å“åº”: ${result.text}`);

      // è§£æ JSON å“åº”
      try {
        // å°è¯•ä»å“åº”ä¸­æå– JSON
        const jsonMatch = result.text.match(/\{[\s\S]*"suggestions"[\s\S]*\}/);
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0]);
          // æ ¼å¼åŒ–è¿”å›ç»“æœ
          const suggestions = parsed.suggestions.slice(0, maxSuggestions).map((text, index) => ({
            id: String.fromCharCode(65 + index), // A, B, C...
            text: text.trim(),
            type: text.length <= 5 ? 'word' : text.length <= 15 ? 'phrase' : 'sentence',
          }));
          return suggestions;
        }
        throw new Error('æ— æ³•è§£æ AI å“åº”');
      } catch (parseError) {
        console.error('âŒ [AI Completion] JSON è§£æå¤±è´¥:', parseError.message);
        // è¿”å›ç©ºæ•°ç»„ï¼Œè€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
        return [];
      }
    } catch (error) {
      console.error('âŒ [AI Completion Error]', error);

      let errorMessage = 'AI è¡¥å…¨æœåŠ¡æš‚æ—¶ä¸å¯ç”¨';
      let errorCode = 'COMPLETION_ERROR';

      if (error.message.includes('ECONNREFUSED') || error.message.includes('connect')) {
        errorMessage = 'AI æœåŠ¡å™¨è¿æ¥å¤±è´¥';
        errorCode = 'CONNECTION_REFUSED';
      } else if (error.message.includes('timeout') || error.message.includes('ETIMEDOUT')) {
        errorMessage = 'AI æœåŠ¡å™¨å“åº”è¶…æ—¶';
        errorCode = 'TIMEOUT';
      }

      const customError = new Error(errorMessage);
      customError.code = errorCode;
      customError.originalError = error.message;
      throw customError;
    }
  };
}

module.exports = new AiService();
